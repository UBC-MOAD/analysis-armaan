{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8894284-c72a-49fa-ab53-bebf63de177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import scipy\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59850ca8-f776-49f9-967f-e00a2dac0c42",
   "metadata": {
    "tags": []
   },
   "source": [
    "Notebook for creating complete HRDPS file after downscaling, for every variable. Produces reconstructed daily HRDPS files and publishes them to the desired filepath."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce0425e-6706-4b10-8096-6ff7bdf860af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb8e2b5-7ff7-4a5f-ae49-18032bc8b106",
   "metadata": {},
   "source": [
    "| Description | HRDPS       | CANRCM      | \n",
    "| ----------- | ----------- | ----------- |\n",
    "| Near-Surface Air Temperature | tair | tas |\n",
    "| Precipitation | precip | pr |\n",
    "| Sea Level Pressure | atmpres | psl |\n",
    "| Near Surface Specific Humidity | qair | huss |\n",
    "| Shortwave radiation | solar | rsds |\n",
    "| Longwave radiation | therm_rad | rlds |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e2a1e95-f91a-41d9-91ab-4915a52a7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [['tair', 'tas', 'Near-Surface Air Temperature'], \n",
    "             ['precip', 'pr', 'Precipitation'], \n",
    "             ['atmpres', 'psl', 'Sea Level Pressure'], \n",
    "             ['qair', 'huss', 'Near Surface Specific Humidity'], \n",
    "             ['solar', 'rsds', 'Shortwave radiation'], \n",
    "             ['therm_rad', 'rlds', 'Longwave radiation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a17f2411-9194-4bdf-8c18-165bce06c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_HRDPS(year, variable):\n",
    "    ##file paths\n",
    "    data_name_hr = variable[0]\n",
    "    files = glob.glob('/results/forcing/atmospheric/GEM2.5/gemlam/gemlam_y' + str(year) + 'm??d??.nc')\n",
    "    files.sort()\n",
    "    \n",
    "    ## 3-hour averaged data\n",
    "    hr = np.zeros( (8*len(files), 266, 256))  \n",
    "    \n",
    "    for i in range(len(files)):\n",
    "        dayX = xr.open_dataset(files[i])\n",
    "        ##adding 1 day of 3-hour averages to new data array\n",
    "        hr[8*i:8*i + 8,:,:] = np.array( dayX[ data_name_hr ] ).reshape(8, 3, 266, 256).mean(axis = 1)\n",
    "    return hr\n",
    "            \n",
    "def import_CANRCM(year, variable):\n",
    "    data_name_can = variable[1]\n",
    "    p_can = '/home/arandhawa/canrcm_' + data_name_can + '_' + str(year) + '.nc'\n",
    "    ##CANRCM import\n",
    "    d1 = xr.open_dataset(p_can)\n",
    "    if year == 2007:\n",
    "        can = d1[data_name_can][16:,140:165,60:85] ##the first two days are removed to be consistent with 2007 HRDPS\n",
    "    elif year == 2008:\n",
    "        can = np.concatenate((d1[data_name_can][:472,140:165,60:85], d1[data_name_can][464:472,140:165,60:85], d1[data_name_can][472:,140:165,60:85] ))\n",
    "    else:\n",
    "        can = d1[data_name_can][:,140:165,60:85]\n",
    "    return can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f2b0782-96e1-4f76-a12a-3d4bab466276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_HRDPS_winds(year):\n",
    "    \n",
    "    ##file paths\n",
    "    files = glob.glob('/results/forcing/atmospheric/GEM2.5/gemlam/gemlam_y' + str(year) + 'm??d??.nc')\n",
    "    files.sort()\n",
    "    ## calculating 3-hour averaged data\n",
    "    hr07_u = np.zeros( (8*len(files), 266, 256)) \n",
    "    hr07_v = np.zeros( (8*len(files), 266, 256)) \n",
    "\n",
    "    for i in range(len(files)):\n",
    "        dayX = xr.open_dataset(files[i])\n",
    "        u = np.array( dayX['u_wind'] ).reshape(8, 3, 266, 256)\n",
    "        v = np.array( dayX['v_wind'] ).reshape(8, 3, 266, 256)\n",
    "        \n",
    "        ##averaging magnitudes/directions rather than averaging conponents\n",
    "        avg_spd = np.mean(np.sqrt(u**2 + v**2), axis = 1)\n",
    "        avg_th = np.arctan2(v.mean(axis = 1), u.mean(axis = 1))\n",
    "        avg_u = avg_spd*np.cos(avg_th)\n",
    "        avg_v = avg_spd*np.sin(avg_th) \n",
    "        \n",
    "        hr07_u[8*i:8*i + 8, : , : ] = avg_u ##adding 3-hour average to new data array\n",
    "        hr07_v[8*i:8*i + 8, : , : ] = avg_v\n",
    "    del avg_u\n",
    "    del avg_v\n",
    "    del u\n",
    "    del v\n",
    "    del avg_spd\n",
    "    del avg_th\n",
    "    \n",
    "    return (hr07_u, hr07_v)\n",
    "\n",
    "def import_CANRCM_winds(year):\n",
    "    \n",
    "    ##data paths\n",
    "    p_can_u = '/home/arandhawa/canrcm_uas_' + str(year) + '.nc'\n",
    "    p_can_v = '/home/arandhawa/canrcm_vas_' + str(year) + '.nc'\n",
    "    ##importing data\n",
    "    d1 = xr.open_dataset(p_can_u)\n",
    "    d2 = xr.open_dataset(p_can_v)\n",
    "    \n",
    "    if year == 2007:\n",
    "        can_u = d1['uas'][16:,140:165,60:85] ##the first two days are removed to be consistent with 2007 HRDPS\n",
    "        can_v = d2['vas'][16:,140:165,60:85]\n",
    "    elif year == 2008:\n",
    "        can_u = np.concatenate((d1['uas'][:472,140:165,60:85], d1['uas'][464:472,140:165,60:85], d1['uas'][472:,140:165,60:85] ))\n",
    "        can_v = np.concatenate((d2['vas'][:472,140:165,60:85], d2['vas'][464:472,140:165,60:85], d2['vas'][472:,140:165,60:85] ))\n",
    "        ##repeating feb 28th twice for leap year\n",
    "    else:\n",
    "        can_u = d1['uas'][:,140:165,60:85]\n",
    "        can_v = d2['vas'][:,140:165,60:85]\n",
    "        \n",
    "    return (can_u, can_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68effed-0b61-4db6-b225-131be5e40d49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PCA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25387353-6d2a-4ecf-8096-efa94a7ab12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##transforms and concatenates two data sets\n",
    "def transform2(data1, data2):\n",
    "    A_mat = transform(data1)\n",
    "    B_mat = transform(data2)\n",
    "    return np.concatenate((A_mat, B_mat), axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5606d7cd-2448-4f77-834a-a0e3a5d29007",
   "metadata": {},
   "outputs": [],
   "source": [
    "##inverse function of transform2 - splits data matrix and returns two data sets\n",
    "def reverse2(matrix, orig_shape):\n",
    "    split4 = int( matrix.shape[0]/2 )\n",
    "    u_data = reverse(matrix[:split4,:], orig_shape) ##reconstructing u_winds from n PCs\n",
    "    v_data = reverse(matrix[split4:,:], orig_shape) ##reconstructing v_winds from n PCs\n",
    "    return (u_data, v_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4bb35be4-5557-4052-99d8-6400c34aad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "##performs PCA analysis using sklearn.pca\n",
    "def doPCA(comp, matrix):\n",
    "    pca = PCA(n_components = comp) ##adjust the number of principle conponents to be calculated\n",
    "    PCs = pca.fit_transform(matrix)\n",
    "    eigvecs = pca.components_\n",
    "    mean = pca.mean_\n",
    "    return (PCs, eigvecs, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e8b428a-0e53-4d14-aa2e-44e2a3aaf8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##data must be converted into a 2D matrix for pca analysis\n",
    "##transform takes a 3D data array (time, a, b) -> (a*b, time)\n",
    "##(the data grid is flattened a column using numpy.flatten)\n",
    "\n",
    "def transform(xarr):\n",
    "    arr = np.array(xarr) ##converting to numpy array\n",
    "    arr = arr.reshape(arr.shape[0], arr.shape[1]*arr.shape[2]) ##reshaping from size (a, b, c) to (a, b*c)\n",
    "    arr = arr.transpose()\n",
    "    return arr\n",
    "\n",
    "def reverse(mat, orig_shape):\n",
    "    arr = np.copy(mat)\n",
    "    arr = arr.transpose()\n",
    "    arr = arr.reshape(-1, orig_shape[1], orig_shape[2]) ##reshaping back to original array shape\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc291b64-f45a-4477-ab98-2f9831741345",
   "metadata": {},
   "outputs": [],
   "source": [
    "##graphing percentage of original data represented by the first n principle conponents\n",
    "def graph_variance(matrix, n):\n",
    "    pcaG = PCA(n_components = n) ##Number of principle conponents to show\n",
    "    PCsG = pcaG.fit_transform(matrix)\n",
    "    plt.plot(np.cumsum(pcaG.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance');\n",
    "    plt.show()\n",
    "    del pcaG\n",
    "    del PCsG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a87b0fa-4cb3-487a-85e6-036472649991",
   "metadata": {},
   "outputs": [],
   "source": [
    "##can be used to visualize principle conponents for u/v winds\n",
    "def graph_nPCs(PCs, eigvecs, n, orig_shape):\n",
    "    fig, ax = plt.subplots(n, 3, figsize=(10, 3*n))\n",
    "    \n",
    "    ax[0, 0].set_title(\"u-conponent\")\n",
    "    ax[0, 1].set_title(\"v-component\")\n",
    "    ax[0, 2].set_title(\"time-loadings\")\n",
    "    \n",
    "    for i in range(n):\n",
    "        mode_u, mode_v = get_mode(PCs, i, orig_shape)\n",
    "        colors = ax[i, 0].pcolormesh(mode_u, cmap = 'bwr')\n",
    "        fig.colorbar(colors, ax = ax[i,0])\n",
    "        colors = ax[i, 1].pcolormesh(mode_v, cmap = 'bwr')\n",
    "        fig.colorbar(colors, ax = ax[i,1])\n",
    "        ax[i, 2].plot(eigvecs[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "##converts PCs (column vectors) to 2d conpoents for u and v wind\n",
    "def get_mode(PCs, n, orig_shape): \n",
    "    split = int(PCs.shape[0]/2)\n",
    "    mode_u = PCs[:split, n].reshape(orig_shape[1], orig_shape[2])\n",
    "    mode_v = PCs[split:, n].reshape(orig_shape[1], orig_shape[2])\n",
    "    return (mode_u, mode_v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881edad9-a1a7-4ad7-901f-c69e2c616837",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Multiple Linear Regression Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e6ef9f5-5c9e-4dcc-8bf0-2c72d898b5f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##functions that use multiple linear regression to fit eigenvectors\n",
    "##takes CANRCM eigenvectors (x1, x2, x3, x4...) and HRDPS eigenvectors (y1, y2, y3...)\n",
    "##For each y from 0:result_size, approximates yn = a0 + a1*x1 + a2*x2 + a3*x3 ... using num_vec x's\n",
    "##getCoefs returns (coeficients, intercept)\n",
    "##fit_modes returns each approximation and the R^2 value of each fit as (results, scores)\n",
    "\n",
    "def getCoefs(vectors, num_vec, data, num_modes, type = 'LS'):  \n",
    "    \n",
    "    X = vectors[0:num_vec,:].T\n",
    "    coefs = np.zeros((num_modes, X.shape[1]))\n",
    "    intercept = np.zeros(num_modes)\n",
    "    \n",
    "    if type == 'LS':\n",
    "        for i in range(num_modes):\n",
    "            y = data[i,:]\n",
    "            reg = LinearRegression().fit(X, y)\n",
    "            coefs[i] = reg.coef_[0:num_vec]\n",
    "            intercept[i] =  reg.intercept_\n",
    "    elif type == 'MAE':\n",
    "        for i in range(num_modes):\n",
    "            y = data[i,:]\n",
    "            reg = QuantileRegressor(quantile = 0.5, alpha = 0, solver = 'highs').fit(X, y)\n",
    "            coefs[i] = reg.coef_[0:num_vec]\n",
    "            intercept[i] =  reg.intercept_\n",
    "    \n",
    "    return (coefs, intercept)\n",
    "\n",
    "\n",
    "def fit_modes(vectors, num_vec, data, result_size, type = 'LS'):  \n",
    "    \n",
    "    X = vectors[0:num_vec,:].T\n",
    "    result = np.zeros((result_size, X.shape[0]))\n",
    "    scores = np.zeros(result_size)\n",
    "    \n",
    "    if type == 'LS':\n",
    "        for i in range(result_size):\n",
    "            y = data[i,:]\n",
    "            reg = LinearRegression().fit(X, y)\n",
    "            result[i] = reg.predict(X)\n",
    "            scores[i] = reg.score(X, y)\n",
    "            \n",
    "    elif type == 'MAE':\n",
    "        for i in range(result_size):\n",
    "            y = data[i,:]\n",
    "            reg = QuantileRegressor(quantile = 0.5, alpha = 0, solver = 'highs').fit(X, y)\n",
    "            result[i] = reg.predict(X)\n",
    "            scores[i] = reg.score(X, y)\n",
    "    \n",
    "    return (result, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30f21fd0-20f1-4988-b53f-55782eb532ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "##returns the ratio of the average energy between two sets of eigenvectors (element-wise)\n",
    "##\"energy\" is defined as value^2 - two sets of eigenvectors with the same \"energy\" would\n",
    "##recreate data with approximately the same kinetic energy (v^2)\n",
    "\n",
    "def getEnergyCoefs(eigs, old_eigs):\n",
    "    coefs = np.sqrt( (old_eigs[0:eigs.shape[0]]**2).mean(axis = 1)/(eigs**2).mean(axis = 1))\n",
    "    return coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12607045-5ca3-4b94-a7db-406de0ee97ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Projection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff87629c-0466-4a0c-9240-9cabd87d5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "##scalar projection of u onto v - with extra 1/norm factor (for math reasons)\n",
    "##projectData projects the data onto each principle conponent, at each time\n",
    "##output is a set of eigenvectors\n",
    "\n",
    "def project(u, v):  \n",
    "    v_norm = np.sqrt(np.sum(v**2))    \n",
    "    return np.dot(u, v)/v_norm**2\n",
    "\n",
    "def projectData(data_mat, new_PCs, n):\n",
    "    time = data_mat.shape[1]\n",
    "    proj = np.empty((n, time))\n",
    "\n",
    "    for j in range(n):\n",
    "        for i in range(time):\n",
    "            proj[j, i] = project(data_mat[:,i], new_PCs[:,j])\n",
    "            \n",
    "    return proj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f945ac0-057d-40b6-9059-4d35e61f9370",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overall Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75b64e1f-7107-4a7f-8aad-db6a337578ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(downscale_mat, mean, can_PCs, can_me, hr_PCs, hr_me, n, r, method = 'LS', EB = 'False'):\n",
    "\n",
    "    coefs = getCoefs(can_me, n + 1, hr_me, r + 1, type = method)\n",
    "    proj = np.concatenate((mean.reshape(1, -1), projectData(downscale_mat - mean, can_PCs, n)), axis = 0)\n",
    "    pred_eigs = np.matmul(coefs[0], proj) + coefs[1].reshape(-1, 1)  ##multiple linear regression output\n",
    "    if (EB == 'true'):\n",
    "        energyCoefs = getEnergyCoefs( fit_modes(can_me, n + 1, hr_me, r + 1, type = method)[0], hr_me)\n",
    "        energyCoefs = energyCoefs.reshape(-1, 1)\n",
    "        pred_eigs = pred_eigs*energyCoefs ##energy balancing\n",
    "    if (EB == 'function'):\n",
    "        energyCoefs = getEnergyCoefs( fit_modes(can_me, n + 1, hr_me, r + 1, type = method)[0] , hr_me)\n",
    "        def f(x):\n",
    "            return np.exp(-x/50)\n",
    "        for x in range(r + 1):\n",
    "            energyCoefs = (energyCoefs - 1)*f(x) + 1\n",
    "        energyCoefs = energyCoefs.reshape(-1, 1)\n",
    "        pred_eigs = pred_eigs*energyCoefs ##energy balancing\n",
    "    \n",
    "    recon = np.matmul(hr_PCs[:,0:r], pred_eigs[1:r+1]) + pred_eigs[0]\n",
    "    data_rec = reverse(recon, (-1, 266, 256))\n",
    "    if (EB == 'constant'):\n",
    "        data_rec *= 1.25\n",
    "    \n",
    "    return data_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6cfb8b65-64f5-4a85-9ef2-54db1ccf3df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct2(downscale_mat, mean, can_PCs, can_me, hr_PCs, hr_me, n, r, method = 'LS', EB = 'false'):\n",
    "\n",
    "    coefs = getCoefs(can_me, n + 1, hr_me, r + 1, type = method)\n",
    "    proj = np.concatenate((mean.reshape(1, -1), projectData(downscale_mat - mean, can_PCs, n)), axis = 0)\n",
    "    pred_eigs = np.matmul(coefs[0], proj) + coefs[1].reshape(-1, 1)  ##multiple linear regression output\n",
    "    if (EB == 'true'):\n",
    "        energyCoefs = getEnergyCoefs( fit_modes(can_me, n + 1, hr_me, r + 1, type = method)[0], hr_me)\n",
    "        energyCoefs = energyCoefs.reshape(-1, 1)\n",
    "        pred_eigs = pred_eigs*energyCoefs ##energy balancing\n",
    "    if (EB == 'function'):\n",
    "        energyCoefs = getEnergyCoefs( fit_modes(can_me, n + 1, hr_me, r + 1, type = method)[0] , hr_me)\n",
    "        def f(x):\n",
    "            return np.exp(-x/50)\n",
    "        for x in range(r + 1):\n",
    "            energyCoefs = (energyCoefs - 1)*f(x) + 1\n",
    "        energyCoefs = energyCoefs.reshape(-1, 1)\n",
    "        pred_eigs = pred_eigs*energyCoefs ##energy balancing\n",
    "    \n",
    "    recon = np.matmul(hr_PCs[:,0:r], pred_eigs[1:r+1]) + pred_eigs[0]\n",
    "    u_data_rec, v_data_rec = reverse2(recon, (-1, 266, 256))\n",
    "    if (EB == 'constant'):\n",
    "        u_data_rec *= 1.3\n",
    "        v_data_rec *= 1.3\n",
    "    \n",
    "    return (u_data_rec, v_data_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f9b69-2238-4867-afed-fdc9e1b0ad7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reconstructing Complete Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3301766b-18bc-451e-99f9-c4c44d32c0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u and v winds done\n"
     ]
    }
   ],
   "source": [
    "data = ()\n",
    "\n",
    "##reconstructing u and v winds\n",
    "hr07_u, hr07_v = import_HRDPS_winds(2007)\n",
    "can07_u, can07_v = import_CANRCM_winds(2007)\n",
    "##PCA on CANRCM 2007\n",
    "can07_mat = transform2(can07_u, can07_v)\n",
    "can07_PCs, can07_eigs, can07_mean = doPCA(100, can07_mat)\n",
    "\n",
    "##PCA on HRDPS 2007\n",
    "hr07_mat = transform2(hr07_u, hr07_v)\n",
    "hr07_PCs, hr07_eigs, hr07_mean = doPCA(100, hr07_mat)\n",
    "\n",
    "## combining the eigenvectors and mean together in one array for analysis\n",
    "can07_me = np.concatenate((can07_mean.reshape(1, -1), can07_eigs))\n",
    "hr07_me = np.concatenate((hr07_mean.reshape(1, -1), hr07_eigs))\n",
    "\n",
    "##calculating average of rows\n",
    "mean_2007 = can07_mat.mean(axis = 0)\n",
    "\n",
    "u_data_rec, v_data_rec = reconstruct2(can07_mat, mean_2007, can07_PCs, can07_me, hr07_PCs, hr07_me, 65, 65, method = 'LS')\n",
    "u_data_rec *= 1.25\n",
    "v_data_rec *= 1.25\n",
    "data += (('u_wind', u_data_rec),)\n",
    "data += (('v_wind', v_data_rec),)\n",
    "print(\"u and v winds done\")\n",
    "\n",
    "del can07_u\n",
    "del can07_v\n",
    "del hr07_u\n",
    "del hr07_v\n",
    "del can07_mat\n",
    "del can07_PCs\n",
    "del can07_eigs\n",
    "del can07_me\n",
    "del can07_mean\n",
    "del u_data_rec\n",
    "del v_data_rec\n",
    "del hr07_mat\n",
    "del hr07_PCs\n",
    "del hr07_eigs\n",
    "del hr07_me\n",
    "del hr07_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a242b9b2-abae-4880-b96a-ba64bc7c1f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tair done\n",
      "precip done\n",
      "atmpres done\n",
      "qair done\n",
      "solar done\n",
      "therm_rad done\n"
     ]
    }
   ],
   "source": [
    "##reconstructing other variables\n",
    "for i in variables:\n",
    "\n",
    "    hr07 = import_HRDPS(2007, i)\n",
    "    can07 = import_CANRCM(2007, i)\n",
    "    \n",
    "    ##PCA on CANRCM 2007\n",
    "    can07_mat = transform(can07)\n",
    "    can07_PCs, can07_eigs, can07_mean = doPCA(100, can07_mat)\n",
    "\n",
    "    ##PCA on HRDPS 2007\n",
    "    hr07_mat = transform(hr07)\n",
    "    hr07_PCs, hr07_eigs, hr07_mean = doPCA(100, hr07_mat)\n",
    "\n",
    "    ## combining the eigenvectors and mean together in one array for analysis\n",
    "    can07_me = np.concatenate((can07_mean.reshape(1, -1), can07_eigs))\n",
    "    hr07_me = np.concatenate((hr07_mean.reshape(1, -1), hr07_eigs))\n",
    "\n",
    "    ##calculating average of rows\n",
    "    mean_2007 = can07_mat.mean(axis = 0)\n",
    "\n",
    "    data_rec = reconstruct(can07_mat, mean_2007, can07_PCs, can07_me, hr07_PCs, hr07_me, 65, 65, method = 'LS')\n",
    "    \n",
    "    data_name_hr = i[0]\n",
    "    if data_name_hr == 'precip' or data_name_hr == 'qair' or data_name_hr == 'solar' or data_name_hr == 'therm_rad':\n",
    "        avg = np.mean(data_rec, axis = 0)\n",
    "        data_rec[data_rec < 0] = 0\n",
    "        avg2 = np.mean(data_rec, axis = 0)\n",
    "        data_rec *= avg/avg2\n",
    "    if data_name_hr == 'solar':\n",
    "        night_solar = np.mean(data_rec[2::8], axis = 0)\n",
    "        data_rec[data_rec < night_solar + 0.1] = 0 \n",
    "        \n",
    "    \n",
    "    data += ((data_name_hr, data_rec),)\n",
    "    print(data_name_hr, \"done\")\n",
    "del can07\n",
    "del hr07\n",
    "del can07_mat\n",
    "del can07_PCs\n",
    "del can07_eigs\n",
    "del hr07_mat\n",
    "del hr07_PCs\n",
    "del hr07_eigs\n",
    "del can07_me\n",
    "del hr07_me\n",
    "del data_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c576ec0c-d2a1-4648-8b5b-d945ec126b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating netcdf files for each day and publishing them to the given path\n",
    "##creates a netcdf file for each day\n",
    "\n",
    "data_var = {}\n",
    "dims = ('time_counter', 'y', 'x')\n",
    "times = np.arange('2007-01-03T00:00', '2008-01-01T00:00', np.timedelta64(3, 'h'), dtype='datetime64[ns]')\n",
    "\n",
    "for i in range(363):\n",
    "    for j in data:\n",
    "        data_var[ j[0] ] = (dims, j[1][8*i:8*i + 8], {})\n",
    "    coords = {'time_counter': times[8*i:8*i + 8], 'y': range(266), 'x': range(256)}\n",
    "    ds = xr.Dataset(data_var, coords)\n",
    "    \n",
    "    d = pd.to_datetime(times[8*i])\n",
    "    if d.month < 10:\n",
    "        month = '0' + str(d.month)\n",
    "    else:\n",
    "        month = str(d.month)\n",
    "    if d.day < 10:\n",
    "        day = '0' + str(d.day)\n",
    "    else:\n",
    "        day = str(d.day)\n",
    "    path = '/ocean/arandhawa/reconstructed_data_2007_p3/recon_y2007m' + month + 'd' + day + '.nc'\n",
    "    \n",
    "    encoding = {var: {'zlib': True} for var in ds.data_vars}\n",
    "    ds.to_netcdf(path, unlimited_dims=('time_counter'), encoding=encoding)\n",
    "    print(\"# of files complete: \", i, end = '/r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0d525b9-24e5-4a49-9358-758d4d601650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('/ocean/arandhawa/reconstructed_data_2007_p3/recon_*')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6c804-d5a5-4eb0-a0e1-1a6d0b987264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
